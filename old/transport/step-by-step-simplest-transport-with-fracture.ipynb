{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step -- Understanding transport with fractures\n",
    "\n",
    "This notebook aims to understand - line by line - how to solve transport on fractures. It will in detail describe every step, and how each step affects future behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Imports\n",
    "We import three modules, `porepy`, `scipy` and `numpy`. These modules are always needed for porepy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import porepy as pp\n",
    "import scipy.sparse as sps\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we will import a particular set of methods used for implicitly solving time-step problems.\n",
    "These are `ImplicitMassMatrix`. We need implicit variants of other discretizers too, but these must be implemented locally. These will be `ImplicitTpfa` and `ImplicitScalarSource`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from porepy.utils.derived_discretizations import implicit_euler as IE_discretizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain\n",
    "Next, we create a simple triangular 2D domain with a single fracture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain(domain):\n",
    "    \"\"\" Create a 2D domain with one fracture.\n",
    "    \n",
    "    Returns:\n",
    "    pp.GridBucket - an object containing the grids (rock and fracture).\n",
    "    \n",
    "    \"\"\"\n",
    "    #eps = 0.1\n",
    "    p = np.array([[0.1, 1.9, 1, 1.9], [0, 0, 0, 0.9]])\n",
    "    e = np.array([[0, 2], [1, 3]])\n",
    "    mesh_args = {'mesh_size_frac': 0.05,\n",
    "                 'mesh_size_bound': 0.1,}\n",
    "    network_2d = pp.FractureNetwork2d(p, e, domain)\n",
    "    gb = network_2d.mesh(mesh_args)\n",
    "    \n",
    "    return gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This domain is from the notebook 'tracer-transport'\n",
    "\n",
    "def create_domain_2(domain={'xmin': -2, 'xmax': 3, 'ymin': -2, 'ymax': 3}):\n",
    "    # First, define 2D coordinates of fracture vertices (np.ndarray: 2 x n)\n",
    "    p = np.array([[-1, 2, 1, 1], [0, 0, 0, 1]])\n",
    "    # Connect the endpoints of fracture vertices by an index mapping (np.ndarray: 2 x num_fracs)\n",
    "    e = np.array([[0, 2], [1, 3]])\n",
    "\n",
    "    # Set domain boundaries\n",
    "    domain = {'xmin': -2, 'xmax': 3, 'ymin': -2, 'ymax': 3}\n",
    "\n",
    "    # Deine a fracture network in 2D\n",
    "    network_2d = pp.FractureNetwork2d(p, e, domain)\n",
    "\n",
    "    # Set preferred mesh size near the fracture and at the boundary\n",
    "    mesh_args = {'mesh_size_frac': 0.2, \n",
    "                 'mesh_size_bound': 0.3,\n",
    "                 'mesh_size_min': 0.1}\n",
    "    #mesh_args = {'mesh_size_frac': 1, \n",
    "    #             'mesh_size_bound': 1,\n",
    "    #             'mesh_size_min': 1}\n",
    "\n",
    "    # Generate a mixed-dimensional mesh\n",
    "    gb = network_2d.mesh(mesh_args)\n",
    "    return gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create simple boundary conditions.\n",
    "Flow from left to right, with no-flow conditions on top and bottom.\n",
    "\n",
    "The method assigns data to each grid in the `GridBucket`, i.e. rock matrix, fractures, etc.\n",
    "\n",
    "We are able to set default parameters for `flow`, `transport` and `mechanics` using `initialize_default_data`. To see what data is being set for the problems, see pp/params/data.py and pp/params/parameter_dictionaries.py.\n",
    "\n",
    "The parameters are stored in a class pp.Parameters. This class is itself stored in the data dictionary on each node and edge in the GridBucket, that is, in the variable `d` in the below loop.\n",
    "To see which parameters are stored on each grid, see `d[pp.PARAMETERS]`.\n",
    "We can store parameters for multiple problems in the dictionary. Each problem is then identified by a keyword. That keyword must also be provided to the discretization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_data(gb, domain, \n",
    "                keyword_flow_storage, keyword_transport_storage,\n",
    "                dt=1/60, t_max=3):\n",
    "    \"\"\" Assign data for low and transport problem\n",
    "    \n",
    "    Parameters\n",
    "    gb (pp.GridBucket)\n",
    "    domain (dict): Dictionary of domain boundaries denoted by\n",
    "                    'xmin', 'xmax', 'ymin', 'ymax'\n",
    "                    \n",
    "    keyword_flow_storage (str): Name of where flow parameters will be\n",
    "                    stored. Usually 'flow'.\n",
    "    keyword_transport_storage (str): Name of where transport parameters\n",
    "                    will be stored. Usually 'transport'\n",
    "    dt (float): time step\n",
    "    t_max (float): End time\n",
    "                            \n",
    "    \n",
    "    Returns\n",
    "    pp.GridBucket with all the assigned data.\n",
    "    \"\"\"\n",
    "    \n",
    "    frac_perm = 1e9 # 1e3\n",
    "    matrix_perm = 1\n",
    "    \n",
    "    # Assign data to the data dictionaries on each grid\n",
    "    for g, d in gb:\n",
    "        \n",
    "        # Permeability \n",
    "        if g.dim == gb.dim_max():\n",
    "            kxx = matrix_perm * np.ones(g.num_cells)\n",
    "        else:\n",
    "            kxx = frac_perm * np.ones(g.num_cells)\n",
    "        perm = pp.SecondOrderTensor(kxx)\n",
    "        \n",
    "        # Next, boundary conditions\n",
    "        b_faces = g.tags['domain_boundary_faces'].nonzero()[0]\n",
    "        bc_val = np.zeros(g.num_faces)\n",
    "        #bc_val = 0 will be applied both to the 2D grid and 1D fracture.\n",
    "        \n",
    "        tol=1e-4\n",
    "        # However, only grids with faces on the global boundary will\n",
    "        # have assigned boundary conditions\n",
    "        # (i.e. if a fracture lies on the boundary, it will get boundary\n",
    "        # conditions assigned.)\n",
    "        if b_faces.size != 0:\n",
    "            \n",
    "            b_face_centers = g.face_centers[:, b_faces]\n",
    "            \n",
    "            # Locate boundaries\n",
    "            left = b_face_centers[0,:] < domain['xmin'] + tol\n",
    "            right = b_face_centers[0, :] > domain['xmax'] - tol\n",
    "            \n",
    "            # Create an array of labels of size = number of boundary faces.\n",
    "            labels = np.array(['neu'] * b_faces.size)\n",
    "            labels[np.logical_or(left, right)] = 'dir'\n",
    "            bc = pp.BoundaryCondition(g, b_faces, labels)\n",
    "            \n",
    "            # On the dirichlet left (inflow) boundary, set its value:\n",
    "            bc_val[b_faces[left]] = 1\n",
    "            \n",
    "        else:  # if the entire grid contains no boundary faces.\n",
    "            bc = pp.BoundaryCondition(g)  # Default conditions.\n",
    "            \n",
    "        \n",
    "        # Assign data to the two problems, flow and transport.\n",
    "        params_flow = {'second_order_tensor': perm,\n",
    "                       'bc': bc,\n",
    "                       'bc_values': bc_val,\n",
    "                        }\n",
    "        pp.initialize_default_data(g, d, 'flow', params_flow,\n",
    "                                  keyword_flow_storage)\n",
    "        \n",
    "        # For implicit euler, the upwind discretization needs an\n",
    "        # 'advection_weight'\n",
    "        w = 1\n",
    "        \n",
    "        # mass weight\n",
    "        unity = np.ones(g.num_cells)\n",
    "        poro = 0.2\n",
    "        # Porosity\n",
    "        if g.dim == gb.dim_max():\n",
    "            porosity = poro * unity\n",
    "            aperture = 1\n",
    "        else:\n",
    "            porosity = (1 - poro) * unity\n",
    "            aperture = np.power(1e-4, gb.dim_max() - g.dim)\n",
    "        \n",
    "        # Assign transport parameters\n",
    "        params_transport = {'bc': bc,\n",
    "                            'bc_values': bc_val,\n",
    "                            'advection_weight': w,\n",
    "                            'time_step': dt,\n",
    "                            't_max': t_max,\n",
    "                            'mass_weight': porosity * aperture,\n",
    "                            }\n",
    "        pp.initialize_default_data(g, d, 'transport', params_transport,\n",
    "                                  keyword_transport_storage)\n",
    "        \n",
    "        # Store the dimension in the dictionary for visualization purposes\n",
    "        d[pp.STATE] = {\"dimension\": g.dim * np.ones(g.num_cells)}\n",
    "            \n",
    "    for e, d in gb.edges():\n",
    "\n",
    "        # Add some required data for fracture problems, which\n",
    "        # is not possible to automatically initialize.\n",
    "        \n",
    "        # The robin coupling (diffusion) needs normal_diffusivity.\n",
    "        # the upwind coupling (advection) has no edge parameters\n",
    "        data = {'normal_diffusivity': 2e1}\n",
    "        d[pp.PARAMETERS] = pp.Parameters(keywords=[keyword_flow_storage,\n",
    "                                                  keyword_transport_storage\n",
    "                                                  ],\n",
    "                                        dictionaries=[data,\n",
    "                                                      data,\n",
    "                                                      ])\n",
    "        # Initialize discretization matrices dictionary\n",
    "        d[pp.DISCRETIZATION_MATRICES] = pp.Parameters(keywords=[keyword_flow_storage,\n",
    "                                                               keyword_transport_storage\n",
    "                                                               ],\n",
    "                                                     dictionaries=[{}, {}])\n",
    "    \n",
    "    return gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the grid and data\n",
    "\n",
    "In this notebook, we are solving two PDEs separately. First, the pressure diffusion equation, then the tracer transport problem.\n",
    "\n",
    "Pressure diffusion:\n",
    "$$ - \\nabla \\cdot (K\\nabla p) = 0$$\n",
    "\n",
    "Tracer transport:\n",
    "$$\\rho C \\frac{\\partial T}{\\partial t} + \\mathbf{v} \\cdot \\nabla T - \\nabla \\cdot (K_T \\nabla T) = 0$$\n",
    "\n",
    "To set up this problem properly in porepy, consider first the pressure diffusion equation. To let porepy understand how to assign the permeability $K$ to the term $-\\nabla \\cdot (K \\nabla p)$, we assign some data to the type of problem we are solving.\n",
    "\n",
    "# THIS NEEDS TO BE UPDATED\n",
    "#### Flow\n",
    "This class of problem is called `flow`. We set the keyword `flow_keyword = flow` in order to easily generate default data for the problem, and ensure that the discretization operators behave properly (i.e. include the $K$ term in the discretization matrix, the correct boundary conditions, etc.).\n",
    "The data itself will be stored in `data[pp.PARAMETERS][keyword_flow]`. Similarly, the discretization matrices are stored in `data[pp.DISCRETIZATION_MATRICES][keyword_flow]`. Edge variables are also stored in the keyword.\n",
    "\n",
    "Next, we give a keyword to the variable we are solving for: `pressure`, by letting `flow_variable = pressure`. This keyword will for instance be used to navigate to the right state in `data[pp.STATE][...]`, where `...` would be `'pressure'` in this case.\n",
    "\n",
    "For the coupling between grids, we designate `edge_variable_flow = 'darcy_flux'` to the pressure diffusion problem.\n",
    "This keyword is used in:\n",
    "* Keyword when initializing edge couplings\n",
    "* Keyword for discretization matrices on edges.\n",
    "\n",
    "The discretization operator keyword on edges are denoted `coupling_operator_key_flow = 'darcy_flux'`\n",
    "\n",
    "---\n",
    "#### Tracer transport\n",
    "Consider the tracer transport equation.\n",
    "This problem is in the class `transport`. We let `transport_keyword = 'transport'`, and use `transport_keyword` when initializing data or discretization operators.\n",
    "Data and operators will be stored under `transport_keyword`.\n",
    "\n",
    "The transport equation consists of an advective term and possibly a diffusive term. These terms needs to be handled by separate coupling terms physically. To accomodate this, we designate `mv_t_advection = 'mortar_transport_advection'` for the advective term, and `mv_t_diffusion = 'mortar_transport_diffusion'` for the diffusive term.\n",
    "These keywords are used in:\n",
    "* Keyword when initializing edge couplings\n",
    "* Keyword for discretization matrices on edges.\n",
    "\n",
    "The transport problem will have two edge variables - one for advection and one for diffusion. These are `edge_variable_transport_diffusion = 'edge_diffusion'` and `edge_variable_transport_advection = 'edge_advection'`.\n",
    "\n",
    "Similarly, their respective discretization operator keywords are `coupling_operator_key_diffusion = 'coupling_operator_transport_diffusion'` and `coupling_operator_key_advection = 'coupling_operator_transport_advection'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords for initializing correct parameters.\n",
    "flow_keyword = 'flow'\n",
    "transport_keyword = 'transport'\n",
    "\n",
    "# Variables for our particular problem. \n",
    "# These variables are keywords for everything related to these parameters:\n",
    "# --- discretization matrices, current state, parameters, etc.\n",
    "flow_variable = 'pressure'\n",
    "transport_variable = 'tracer'\n",
    "\n",
    "# Operator keys:\n",
    "flow_operator_key = 'diffusion'\n",
    "\n",
    "advection_operator_key = 'advection'\n",
    "mass_operator_key = 'mass'\n",
    "diffusion_operator_key = 'diffusion_tracer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the domain and assign data\n",
    "#domain={'xmin': 0, 'xmax': 2, 'ymin': -1, 'ymax': 1}\n",
    "domain2 = {'xmin': -2, 'xmax': 3, 'ymin': -2, 'ymax': 3}\n",
    "gb = create_domain_2(domain2)\n",
    "#gb = create_domain(domain=domain)\n",
    "gb = assign_data(gb, domain=domain2,\n",
    "                keyword_flow_storage=flow_keyword,\n",
    "                keyword_transport_storage=transport_keyword,\n",
    "                )\n",
    "\n",
    "# Initial conditions for tracer:\n",
    "for g, d in gb:\n",
    "    t_0 = np.zeros(g.num_cells)\n",
    "    state = {transport_variable: t_0}\n",
    "    pp.set_state(d, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discretization objects for pressure diffusion\n",
    "Create discretization objects for grid and coupling conditions for the pressure diffusion problem\n",
    "\n",
    "For the diffusion term, a `RobinCoupling` is used.\n",
    "This class needs the keyword for the diffusion term in the mortar grid, `mv_f_diffusion` and the discretization objects for the master and slave grids. Here, I use the same discretization on all grids, i.e. `tpfa_flow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pressure diffusion discretization\n",
    "flow_discretization = pp.Tpfa(flow_keyword)\n",
    "# Coupling:\n",
    "edge_discretization_flow = pp.RobinCoupling(flow_keyword, \n",
    "                                            flow_discretization, \n",
    "                                            flow_discretization)\n",
    "\n",
    "# Variable name for the interface variable\n",
    "edge_variable_flow = 'darcy_flux'\n",
    "# Name for the discretization operator for the coupling term.\n",
    "coupling_operator_key_flow = 'darcy_flux'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discretization objects for tracer advection-diffusion\n",
    "For the transport problem, since it is time-dependent, we need to modify several of the discretization objects to conform to a certain way of solving the implicit problem.\n",
    "\n",
    "Essentially, we may consider a time-dependent system, \n",
    "$$\\frac{\\partial u}{\\partial t} = F(u)$$\n",
    "which we want to solve using backward euler:\n",
    "$$\\frac{u^{t + \\Delta t} - u^{t}}{\\Delta t} = F(u^{t + \\Delta t})$$\n",
    "we can re-order the terms:\n",
    "$$u^{t + \\Delta t} - \\Delta t F(u^{t + \\Delta t}) = u^{t}$$\n",
    "let $x=u^{t + \\Delta t}$ and $b = u^{t}$:\n",
    "$$x + \\Delta t F x = b$$\n",
    "\n",
    "We see that every term except the previous time step needs to be multiplied by $\\Delta t$.\n",
    "Here, the operator $F$ will consist of the discretization objects for the advective term, diffusive term, etc.\n",
    "\n",
    "To assemble this system, we would like to multiply the appropriate terms by $\\Delta t$. This is done by overriding the methods in the discretization operators that we will use.\n",
    "\n",
    "Consider\n",
    "$$\\rho C \\frac{\\partial T}{\\partial t} + \\mathbf{v} \\cdot \\nabla T - \\nabla \\cdot (K_T \\nabla T) = 0$$\n",
    "\n",
    "* `mass_term`: $\\rho C \\frac{\\partial T}{\\partial t}$, use: `ImplicitMassMatrix`\n",
    "* `advection_term`: $\\mathbf{v} \\cdot \\nabla T$, use: `ImplicitUpwind`\n",
    "* `diffusion_term`: $- \\nabla \\cdot (K_T \\nabla T)$, use: `ImplicitTpfa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override methods for implicit time-stepping:\n",
    "class ImplicitTpfa(pp.Tpfa):\n",
    "    \"\"\"\n",
    "    Multiply all contributions by the time step.\n",
    "    \"\"\"\n",
    "\n",
    "    def assemble_matrix_rhs(self, g, data):\n",
    "        \"\"\" Overwrite TPFA method to be consistent with the Biot dt convention.\n",
    "        \"\"\"\n",
    "        a, b = super().assemble_matrix_rhs(g, data)\n",
    "        dt = data[pp.PARAMETERS][self.keyword][\"time_step\"]\n",
    "        a = a * dt\n",
    "        b = b * dt\n",
    "        return a, b\n",
    "\n",
    "    def assemble_int_bound_flux(\n",
    "        self, g, data, data_edge, grid_swap, cc, matrix, rhs, self_ind\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Overwrite the TPFA method to be consistent with the Biot dt convention\n",
    "        \"\"\"\n",
    "        dt = data[pp.PARAMETERS][self.keyword][\"time_step\"]\n",
    "\n",
    "        div = g.cell_faces.T\n",
    "\n",
    "        bound_flux = data[pp.DISCRETIZATION_MATRICES][self.keyword][\"bound_flux\"]\n",
    "        # Projection operators to grid\n",
    "        mg = data_edge[\"mortar_grid\"]\n",
    "\n",
    "        if grid_swap:\n",
    "            proj = mg.mortar_to_slave_int()\n",
    "        else:\n",
    "            proj = mg.mortar_to_master_int()\n",
    "\n",
    "        if g.dim > 0 and bound_flux.shape[0] != g.num_faces:\n",
    "            # If bound flux is gven as sub-faces we have to map it from sub-faces\n",
    "            # to faces\n",
    "            hf2f = pp.fvutils.map_hf_2_f(nd=1, g=g)\n",
    "            bound_flux = hf2f * bound_flux\n",
    "        if g.dim > 0 and bound_flux.shape[1] != proj.shape[0]:\n",
    "            raise ValueError(\n",
    "                \"\"\"Inconsistent shapes. Did you define a\n",
    "            sub-face boundary condition but only a face-wise mortar?\"\"\"\n",
    "            )\n",
    "\n",
    "        cc[self_ind, 2] += dt * div * bound_flux * proj\n",
    "    \n",
    "    def assemble_int_bound_source(\n",
    "        self, g, data, data_edge, grid_swap, cc, matrix, rhs, self_ind\n",
    "    ):\n",
    "        \"\"\" Abstract method. Assemble the contribution from an internal\n",
    "        boundary, manifested as a source term.\n",
    "        The intended use is when the internal boundary is coupled to another\n",
    "        node in a mixed-dimensional method. Specific usage depends on the\n",
    "        interface condition between the nodes; this method will typically be\n",
    "        used to impose flux continuity on a lower-dimensional domain.\n",
    "        Implementations of this method will use an interplay between the grid on\n",
    "        the node and the mortar grid on the relevant edge.\n",
    "        Parameters:\n",
    "            g (Grid): Grid which the condition should be imposed on.\n",
    "            data (dictionary): Data dictionary for the node in the\n",
    "                mixed-dimensional grid.\n",
    "            data_edge (dictionary): Data dictionary for the edge in the\n",
    "                mixed-dimensional grid.\n",
    "            grid_swap (boolean): If True, the grid g is identified with the @\n",
    "                slave side of the mortar grid in data_adge.\n",
    "            cc (block matrix, 3x3): Block matrix for the coupling condition.\n",
    "                The first and second rows and columns are identified with the\n",
    "                master and slave side; the third belongs to the edge variable.\n",
    "                The discretization of the relevant term is done in-place in cc.\n",
    "            matrix (block matrix 3x3): Discretization matrix for the edge and\n",
    "                the two adjacent nodes.\n",
    "            rhs (block_array 3x1): Right hand side contribution for the edge and\n",
    "                the two adjacent nodes.\n",
    "            self_ind (int): Index in cc and matrix associated with this node.\n",
    "                Should be either 1 or 2.\n",
    "        \"\"\"\n",
    "        mg = data_edge[\"mortar_grid\"]\n",
    "\n",
    "        if grid_swap:\n",
    "            proj = mg.mortar_to_master_int()\n",
    "        else:\n",
    "            proj = mg.mortar_to_slave_int()\n",
    "        dt = data[pp.PARAMETERS][self.keyword][\"time_step\"]\n",
    "        cc[self_ind, 2] -= proj * dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the discretization objects for advection-diffusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization objects\n",
    "\n",
    "# First argument, keyword, is where to get parameters from\n",
    "# and store discretization matrices to.\n",
    "# Second argument, variable, is where the previous state (d[pp.STATE][variable]) is stored.\n",
    "mass_discretization = IE_discretizations.ImplicitMassMatrix(keyword=transport_keyword,\n",
    "                                                            variable=transport_variable)\n",
    "\n",
    "# Here, we might need to define,\n",
    "# data[pp.PARAMETERS][variable_t]['advection_weight'] ...\n",
    "advection_discretization = IE_discretizations.ImplicitUpwind(transport_keyword)\n",
    "\n",
    "diffusion_discretization = ImplicitTpfa(transport_keyword)\n",
    "\n",
    "# ----\n",
    "# EDGE discretizations\n",
    "# the first arg is where to get parameters from and store discretization matrices to\n",
    "# Second and third args are master and slave discretizations, respectively.\n",
    "edge_discretization_transport_diffusion = pp.RobinCoupling(transport_keyword,\n",
    "                                                           diffusion_discretization,\n",
    "                                                           diffusion_discretization)\n",
    "# Variable name for the interface variable\n",
    "edge_variable_transport_diffusion = 'edge_diffusion'\n",
    "# Name for the discretization operator for the coupling term\n",
    "coupling_operator_key_diffusion = 'coupling_operator_transport_diffusion'\n",
    "\n",
    "edge_discretization_transport_advection = IE_discretizations.ImplicitUpwindCoupling(transport_keyword)\n",
    "\n",
    "edge_variable_transport_advection = 'edge_advection'\n",
    "coupling_operator_key_advection = 'coupling_operator_transport_advection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribute the discretization objects\n",
    "\n",
    "The various discretization objects needs to be added to the grid bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g, d in gb:\n",
    "    \n",
    "    # Assign primary variables on the grid\n",
    "    d[pp.PRIMARY_VARIABLES] = {\n",
    "        flow_variable: {\"cells\": 1, \"faces\": 0},\n",
    "        transport_variable: {\"cells\": 1, \"faces\": 0},\n",
    "    }\n",
    "    \n",
    "    # Assign discretization operators for each variable\n",
    "    d[pp.DISCRETIZATION] = {\n",
    "        flow_variable: {\n",
    "            flow_operator_key: flow_discretization,\n",
    "        },\n",
    "        transport_variable: {\n",
    "            mass_operator_key: mass_discretization,\n",
    "            advection_operator_key: advection_discretization,\n",
    "            diffusion_operator_key: diffusion_discretization\n",
    "        }\n",
    "    }\n",
    "\n",
    "    for e, d in gb.edges():\n",
    "        g1, g2 = gb.nodes_of_edge(e)\n",
    "        d[pp.PRIMARY_VARIABLES] = {\n",
    "            edge_variable_flow: {\"cells\": 1},\n",
    "            edge_variable_transport_diffusion: {\"cells\": 1},\n",
    "            edge_variable_transport_advection: {\"cells\": 1}\n",
    "        }\n",
    "        \n",
    "        d[pp.COUPLING_DISCRETIZATION] = {\n",
    "            coupling_operator_key_flow: {\n",
    "                g1: (flow_variable, flow_operator_key),\n",
    "                g2: (flow_variable, flow_operator_key),\n",
    "                e: (edge_variable_flow, edge_discretization_flow)\n",
    "            },\n",
    "            coupling_operator_key_diffusion: {\n",
    "                g1: (transport_variable, diffusion_operator_key),\n",
    "                g2: (transport_variable, diffusion_operator_key),\n",
    "                e: (edge_variable_transport_diffusion, edge_discretization_transport_diffusion)\n",
    "            },\n",
    "            coupling_operator_key_advection: {\n",
    "                g1: (transport_variable, advection_operator_key),\n",
    "                g2: (transport_variable, advection_operator_key),\n",
    "                e: (edge_variable_transport_advection, edge_discretization_transport_advection)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembler for flow and transport problem\n",
    "To exclusively solve the flow problem (we need the darcy flux to solve the transport problem), we use a filter on the assembler.\n",
    "\n",
    "We set up two assemblers, one for each problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_flow = pp.Assembler(gb, active_variables=[\n",
    "                                    flow_variable, \n",
    "                                    edge_variable_flow\n",
    "                                                    ])\n",
    "\n",
    "assembler_transport = pp.Assembler(gb, \n",
    "                                   active_variables=[\n",
    "                                       transport_variable,\n",
    "                                       edge_variable_transport_diffusion,\n",
    "                                       edge_variable_transport_advection,\n",
    "                                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, solve the flow problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_flow.discretize()\n",
    "A_flow, b_flow = assembler_flow.assemble_matrix_rhs()\n",
    "pressure = sps.linalg.spsolve(A_flow, b_flow)\n",
    "assembler_flow.distribute_variable(pressure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the flux field and make this information available to the transport solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.fvutils.compute_darcy_flux(gb, lam_name='darcy_flux', keyword_store=transport_keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporter_pressure = pp.Exporter(gb, name='flow', folder='advection_diffusion')\n",
    "#exporter_pressure.write_vtk(flow_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, solve the transport problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_transport.discretize()\n",
    "\n",
    "# Test the first time-step:\n",
    "#A_transport, b_transport = assembler_transport.assemble_matrix_rhs()\n",
    "#tracer = sps.linalg.spsolve(A_transport, b_transport)\n",
    "# Distributing variable changes the state.\n",
    "#assembler_transport.distribute_variable(tracer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a new exporter for the transport problem. \n",
    "\n",
    "Make a list of time steps to visualize the time evolution of tracer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer_folder='adv-diff-testing'\n",
    "export_transport = pp.Exporter(gb, name='tracer', folder=tracer_folder)\n",
    "export_fields = ['tracer']\n",
    "\n",
    "time_steps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for main grid\n",
    "g2 = gb.grids_of_dimension(gb.dim_max())[0]\n",
    "d2 = gb.node_props(g2)\n",
    "params2 = d2[pp.PARAMETERS][transport_keyword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'mass_weight', 'second_order_tensor', 'bc', 'bc_values', 'darcy_flux', 'time_step', 'advection_weight', 't_max'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_every = 1\n",
    "n_steps = int(np.round(params2[\"t_max\"] / params2[\"time_step\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export the initial state (initial conditions set at beginning of script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haakon/anaconda3/lib/python3.7/site-packages/vtk/util/numpy_support.py:137: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  assert not numpy.issubdtype(z.dtype, complex), \\\n"
     ]
    }
   ],
   "source": [
    "export_transport.write_vtk('tracer', time_step=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use backward euler for time stepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_steps):\n",
    "    \n",
    "    A_transport, b_transport = assembler_transport.assemble_matrix_rhs()\n",
    "    tracer = sps.linalg.spsolve(A_transport, b_transport)\n",
    "    \n",
    "    # Distribute and export\n",
    "    assembler_transport.distribute_variable(tracer)\n",
    "\n",
    "    if np.isclose(i % save_every, 0):\n",
    "        export_transport.write_vtk(['tracer'], time_step=int(i // save_every))\n",
    "\n",
    "    \n",
    "        \n",
    "# Export the time history as a separate file.\n",
    "# This will produce a file 'tracer.pvd', which should be used for visualization\n",
    "time_steps = np.arange(\n",
    "    0, params2[\"t_max\"] + params2[\"time_step\"], save_every * params2[\"time_step\"]\n",
    ")\n",
    "export_transport.write_pvd(time_steps) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
